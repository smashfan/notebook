```python
class My_loss(nn.Module):
    def __init__(self):
        super().__init__()
        
    def forward(self, x, y):
        return torch.sum(torch.pow((x - y), 2))

S = torch.nn.Sigmoid()
# x = torch.tensor(1)
# y=S(-S(-x-1)-1)
# print(y)
# y = S(x)  # 元素层面的操作
# print(y)
# print((0.2194-0.5)**2+(0.25-0.2462)**2)
x = torch.tensor([0.,1.])
w = torch.tensor([-1.],requires_grad=True)
b = torch.tensor([-1.],requires_grad=True)

# [1,10]*[10,1]得到一维的数
o = S(w*S(w*x+b)+b)
# 得到loss，label和输出做均方差
print(o)
loss = My_loss()
loore=loss(torch.tensor([0.5,0.25]),o)
# 得到梯度信息
loore.backward()
print(loore)
print("o.shape = ",o.shape)
print("loss.shape = ",loore.shape)
print(w.grad)
print(b.grad)
```

