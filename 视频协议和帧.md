在线观看其实是一种**视频协议**。也就是只有在有网络时通过浏览器或者移动端APP才能看到的视频。常见的直播流协议有：RTMP、RTSP、HTTP 等；常见的点播协议有：MP4、FLV、HLS 等。在连接视频协议时，除了音视频频流和metadata之外，可能还会携带播放的信令。



### 打破我的想法

视频编码的用法

假设我们有一个 1920 * 1080 大小，时长 2 个小时的电影。我们不妨算一下其数据量的大小，每秒钟的图片张数姑且按 25 算，1920 * 1080 * 3 * 25 * 2 * 60 * 60，大约是 463 个G。而互联网的流量，是需要传播的，假设这一个视频要从 internet 内的 A 传送到 B，463 个 G 的带宽是什么概念。因此，我们便有了视频的编码，而所谓编码，其本质就是将数据压缩，进而减少带宽或存储空间的占用。



视频播放器播放一个互联网上的视频文件，需要经过以下几个步骤：

- 解协议
- 解封装
- 解码视音频
- 视音频同步

如果播放本地文件则不需要解协议，为以下几个步骤：

- 解封装
- 解码视音频
- 视音频同步
- ![img](https://pic3.zhimg.com/80/v2-c1c8cbd7e87f3cc7cb016a713fdb5162_720w.jpg)

我们最开始学习的[彩色图像的原理](https://link.zhihu.com/?target=https%3A//github.com/leandromoreira/digital_video_introduction/blob/master/README-cn.md%23%E5%9F%BA%E6%9C%AC%E6%9C%AF%E8%AF%AD)使用的是 **RGB 模型**，但也有其他模型。有一种模型将亮度（光亮）和色度（颜色）分离开，它被称为 **YCbCr\***。





现实世界中的声音图像采样后经过音视频压缩技术压缩而成的码流称为ES流（Elementary Stream），ES流中包含有解码器解码文件必须的信息，比如视频宽高，采样格式，声音的采样率，声道等等。为了方便传输，播放，将音视频ES数据打包到一个文件中，这个文件称之为音视频ES流的封装，常见的音视频封装格式有：MP3，MP4，AVI，MKV，FLV，RMVB，TS，PS等等。



解码器源源不断地读取ES流，解码输出，音乐美妙，画面流畅，这一切看起来都是那么的和谐。播放的时候，为了音视频同步，引入了PTS和DTS，即Presentation Time Stamp和Decode Time Stamp 。有的解码器要求将PTS放在ES流的前面几个字节，有的解码器要求将PTS通过描述信息，用描述信息头的方式传入，颇似带内和带外传输



这就要求将ES流分成一段一段的，用来将PTS和该段的ES流对应起来，这就是所称的分帧，组帧Framing操作。音频的Framing较为简单，SYNC WORD加上两个SYNC WORD之间的部分就是一帧，SYNC WORD也相对固定。 图像的Framing相对复杂，除上述原因之外，有的解码器要求严格按照图像的边界来描述ES流，如H264的流必须以00 00 00 01 或 00 00 01开始。再者，有些文件在打包的时候，只包含了ES流，无封装格式，比如一些MPEG格式的视频。这些MPEG格式的视频文件后缀可以是mpgv，mpv，mp1v，m1v，mp2v，m2v。所以，这才有了本文需要讲述的packet parse。本文分析基于FFMPEG4.2.2。
https://blog.csdn.net/intel1985/article/details/112864008