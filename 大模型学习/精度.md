fp16，bf16

### FP16

FP16也叫做 float16，两种叫法是完全一样的，全称是Half-precision floating-point(半精度浮点数)，在IEEE 754标准中是叫做binary16，简单来说是用16位二进制来表示的浮点数，来看一下是怎么表示的(以下图都来源于维基百科[[2\]](https://zhuanlan.zhihu.com/p/657886517#ref_2))：



- Sign(符号位): 1 位，0表示整数；1表示负数。
- Exponent(指数位)：5位，简单地来说就是表示整数部分，范围为00001(1)到11110(30)，正常来说整数范围就是 21−230 ，但其实为了指数位能够表示负数，引入了一个偏置值，偏置值是一个固定的数，它被加到实际的指数上，在二进制16位浮点数中，偏置值是 15。这个偏置值确保了指数位可以表示从-14到+15的范围即 2−14−215 ，而不是1到30，注：当指数位都为00000和11111时，它表示的是一种特殊情况，在IEEE 754标准中叫做非规范化情况，后面可以看到这种特殊情况怎么表示的。
- Fraction(尾数位)：10位，简单地来说就是表示小数部分，存储的尾数位数为10位，但其隐含了首位的1，实际的尾数精度为11位，这里的隐含位可能有点难以理解，简单通俗来说，假设尾数部分为1001000000，为默认在其前面加一个1，最后变成1.1001000000然后换成10进制就是:

### BF16

BF16也叫做bfloat16(这是最常叫法)，其实叫“BF16”不知道是否准确，全称brain floating point，也是用16位二进制来表示的，是由Google Brain开发的，所以这个brain应该是Google Brain的第二个单词。和上述FP16不一样的地方就是指数位和尾数位不一样，看图：

- Sign(符号位): 1 位，0表示整数；1表示负数
- Exponent(指数位)：8位，表示整数部分，偏置值是 127
- Fraction(尾数位)：7位，表示小数部分，也是隐含了首位的1，实际的尾数精度为8位

这里要注意一下，并不是所有的硬件都支持bfloat16，因为它是一个比较新的数据类型，在 NVIDIA GPU 上，只有 Ampere 架构以及之后的GPU 才支持，如何判断呢？很简单：