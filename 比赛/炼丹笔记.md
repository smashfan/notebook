# 深度学习训练loss下降，准确度却保持不变是什么原因？

1.验证集上存在错误；

2.样本中存在训练难度有较大gap的样本。换句话说：有的样本比较容易训，有的样本比较难训，那么对于某些比较容易训练的样本，本来对这个样本的置信度是60%，现在训到了90%。但是对于那种难训练(难以识别)的样本来说，它们的置信度可能本来是31%，现在是32%，差别不大。可以尝试通过一些tricks来改善，比如一些数据增强的方式，增加样本的训练难度，提高对潜在特征的挖掘；使用如focus loss之类的损失函数(或者你模范着自己写一下)，迫使模型放更多的精力在难以训练的样本上(本质上是难训练的样本提供的loss更多)。



### 训练网络

常见的训练代码，以swin-transformer为例：

```
CUDA_VISIBLE_DEVICES=2 python tools/train.py configs/swin/mask_rcnn_swin-t-p4-w7_fpn_1x_coco.py
1
```

CUDA_VISIBLE_DEVICES=1：指定仅gpu1对程序可见（使用单块GPU进行训练）
--work-dir：保存模型pth的路径
--resume-from：用于恢复的checkpoint文件
--auto-resume：自动从最近一次保存的checkpoint文件恢复
--validate：是否在训练中建立checkpoint的时候对该checkpoint进行评估（evaluate）（未采用分布式训练时，--validate无效）
--launcher：分布式训练的任务启动器

### K折交叉验证，用于选择模型

当数据过少的时候，为了利用所有的数据去训练，可以用

k折交叉验证

交叉验证主要是为了评估算法性能的好坏，并不是说要从这k个模型里选一个作为最后的解。主要是防止训练集和测试集选择不佳而导致不能很好的反映算法的性能。

1、交叉验证可以有效评估模型的质量
2、交叉验证可以有效选择在数据集上表现最好的模型
3、交叉验证可以有效避免过拟合和欠拟合
 • 欠拟合（Underfitting）是指模型不能获取数据集的主要信息，在训练集及测试集上的表示都十分糟糕。
 • 过拟合（Overfitting）是指模型不仅获取了数据集的信息还提取了噪声数据的信息是的模型在训练集有非常好的表现但在测试集上的表现及其糟糕。

       所以可以得出一个较为草率的结论：一个最佳的ML模型在训练集和测试集上都有较好的表现。



api：StratifiedKFold和KFold

StratifiedKFold则是在KFold的基础上，加入了`分层抽样`的思想，使得测试集和[训练集](https://so.csdn.net/so/search?q=训练集&spm=1001.2101.3001.7020)有相同的数据分布，因此表现在算法上，StratifiedKFold需要`同时输入数据和标签`，便于统一训练集和测试集的分布

### 过拟合的特点

曲线下降，到达低点然后上升

一般是过拟合，可以尝试调低学习率或者多用一些数据增广数据预处理等手段。如果还不行，那就说明有可能程序出现错误。



### batch的选择

batch_size是训练神经网络中的一个重要的超参数，该值决定了一次将多少数据送入神经网络参与训练。在论文[1]中，作者通过实验发现，当batch_size的值与学习率的值呈线性关系时，收敛精度几乎不受影响。在训练ImageNet数据时，大部分的神经网络选择的初始学习率为0.1，batch_size是256，所以根据实际的模型大小和显存情况，可以将学习率设置为0.1*k,batch_size设置为256*k

越大越好？

### 网络调参

网络调参。网络参数的设置直接影响着网络模型的分类精度，需要调节的参数有好多，比如：batch_size、learning rate、隐层units数、网络层数、L1／L2正则项参数等等，这些参数都需要根据训练过程进行调节；另外选择好的优化算法可以使模型产生好的效果，包括反向传播优化算法、学习率衰减等等。