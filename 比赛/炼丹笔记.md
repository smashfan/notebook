# 深度学习训练loss下降，准确度却保持不变是什么原因？

1.验证集上存在错误；

2.样本中存在训练难度有较大gap的样本。换句话说：有的样本比较容易训，有的样本比较难训，那么对于某些比较容易训练的样本，本来对这个样本的置信度是60%，现在训到了90%。但是对于那种难训练(难以识别)的样本来说，它们的置信度可能本来是31%，现在是32%，差别不大。可以尝试通过一些tricks来改善，比如一些数据增强的方式，增加样本的训练难度，提高对潜在特征的挖掘；使用如focus loss之类的损失函数(或者你模范着自己写一下)，迫使模型放更多的精力在难以训练的样本上(本质上是难训练的样本提供的loss更多)。



### 训练网络

常见的训练代码，以swin-transformer为例：

```
CUDA_VISIBLE_DEVICES=2 python tools/train.py configs/swin/mask_rcnn_swin-t-p4-w7_fpn_1x_coco.py
1
```

CUDA_VISIBLE_DEVICES=1：指定仅gpu1对程序可见（使用单块GPU进行训练）
--work-dir：保存模型pth的路径
--resume-from：用于恢复的checkpoint文件
--auto-resume：自动从最近一次保存的checkpoint文件恢复
--validate：是否在训练中建立checkpoint的时候对该checkpoint进行评估（evaluate）（未采用分布式训练时，--validate无效）
--launcher：分布式训练的任务启动器

K折交叉验证，用于选择模型

交叉验证主要是为了评估算法性能的好坏，并不是说要从这k个模型里选一个作为最后的解。主要是防止训练集和测试集选择不佳而导致不能很好的反映算法的性能。





### 过拟合的特点

曲线下降，到达低点然后上升

一般是过拟合，可以尝试调低学习率或者多用一些数据增广数据预处理等手段。如果还不行，那就说明有可能程序出现错误。



### batch的选择

batch_size是训练神经网络中的一个重要的超参数，该值决定了一次将多少数据送入神经网络参与训练。在论文[1]中，作者通过实验发现，当batch_size的值与学习率的值呈线性关系时，收敛精度几乎不受影响。在训练ImageNet数据时，大部分的神经网络选择的初始学习率为0.1，batch_size是256，所以根据实际的模型大小和显存情况，可以将学习率设置为0.1*k,batch_size设置为256*k

越大越好？