# 英伟达 Nsight 

>https://developer.nvidia.com/nsight-compute

**必须使用Roofline模型确定神经网络是算术界限还是内存界限。如果两者都不是，那么升级到更强大的机器就没有价值了**

总结

- 矩阵-矩阵乘法是神经网络训练和推理中最常用的运算。矩阵乘法的次数几乎是神经网络层数的3n。因此，尽可能快地计算这些是很重要的。
- 在神经网络中，矩阵是非常大的。因此，我们总是使用GPU来加速矩阵乘法。为了做到这一点，我们必须了解GPU的ops:字节比，并设计层的算法强度要大于ops:字节比，如果可能的话。
- 为了达到使用所有张量核心的峰值算术性能，矩阵的维数也必须满足NVIDIA架构对使用张量核心的要求。通常，它是8 (FP16算术)或16 (FP32算术)的倍数。最好查看文档以确保满足需求。
- 您应该确定应用程序是内存绑定还是算术绑定。如果两者都不是，那么升级到更强大的GPU就没有意义了。否则，我们可以通过升级进一步加速。
- 了解硬件功能及其对最大化性能的要求将有助于明智地选择矩阵维数和批大小。这将导致神经网络的设计，使训练可以在最短的时间内以最低的成本完成。

实验设计：

（1）  基于MindSpore或者MindSpore Lite实现相关算法，并考虑在不同框架下进行实验效果对比。

（2）  在适配和加速算法的实现中，加入华为设备。



Conv->BN->ReLU 就会融合成一个算子

 卷积核复用

因此卷积和全连接**实质上都是一组线性转换**，但是卷积相比全连接而言，其参数矩阵更加稀疏，kernel matrix 中很多为零（sparse connectivity），同时非零部分的参数实际上是共享的（parameter sharing）。这两个特点让卷积**可以大大减少参数的数量，同时同一套参数（卷积核）在多个地方复用更有利于捕捉局部的特征**。相比之下全连接的参数更多，每个参数只负责唯一的连接，计算量、内存需求增大的同时也更加难以训练。