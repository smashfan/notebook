LaLaRAND: Flexible Layer-by-Layer CPU/GPU Scheduling for Real-Time DNN Tasks

摘要--深层神经网络（DNN）在各种机器学习（ML）任务中显示出显著的成功，对许多安全关键的实时嵌入式系统非常有用。在实时嵌入式系统上执行DNN的首要设计目标是用有限的计算资源提供最坏情况下的时间保证。然而，最先进的ML框架几乎没有利用异构计算资源（即CPU和GPU）来改善实时DNN任务的可调度性，这是因为有几个因素，其中包括粗粒度的资源分配模型（每个任务一个资源），DNN在CPU和GPU上执行的不对称性，以及缺乏调度性感知的CPU/GPU分配方案。据我们所知，本文首次提出了解决上述三个主要障碍的研究，并考察了它们对调度性改进的合作效果。在本文中，我们提出了LaLaRAND，一个实时的层级DNN调度框架，它通过将CPU友好的量化与细粒度的CPU/GPU分配方案（每层一个资源）紧密结合，实现了单个DNN层的灵活的CPU/GPU调度，同时在不影响时间保证的情况下减轻了精度损失。我们在最先进的ML框架上实施并评估了LaLaRAND，证明了它在使更多的DNN任务集可被调度方面的有效性，比现有的方法高出56%和80%。
和80%，与现有的方法和基线（vanilla PyTorch）相比，性能（推断准确率）的差异只有-0.4%。



贡献。据我们所知，本文提出了第一个将CPU友好量化与层级CPU/GPU分配方案相结合的方法，为改善实时DNN任务的可调度性做出了合作贡献。本文的贡献可以概括为以下几点。

- 
- 我们通过深入的案例研究，证明了CPU和GPU之间显著的性能不平衡，采用CPU友好量化的机会，以及层级资源分配的重要性，同时考虑到其对调度性和推理准确性的影响（第二节）。
- 我们提出了一个新的系统抽象，以透明的方式支持CPU和GPU上单个DNN层的调度（第三部分）。
- 我们创建了一个离线的逐层CPU/GPU分配算法，它不仅提供了时间保证，还提高了调度性能（第四部分）
- 我们开发了一个在线的CPU/GPU分配方案，支持在CPU和GPU之间重新分配DNN层，以减轻由于CPU友好量化而造成的精度损失，而不损害任何时序保证（第五部分）。
- 从我们的实验结果来看，我们发现LaLaRAND明显优于采用标准DNN模型的最先进的ML框架，DNN任务集的可调度性提高了80%（第六节）。