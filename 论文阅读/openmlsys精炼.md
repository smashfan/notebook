# 4.计算图

> https://openmlsys.github.io/chapter_computational_graph/background_and_functionality.html

作用：

1.**对于输入数据、算子和算子执行顺序的统一表达**

2.**定义中间状态和模型状态**

3.**自动化计算梯度**

4.**优化程序执行**





### 中间表示（IR）

中间表示(IR)，是编译器用于表示源代码的数据结构或代码，是程序编译过程中介于源语言和目标语言之间的程序表示。几乎所有的编译器都需要某种形式的中间表示，来对被分析、转换和优化的代码进行建模。在编译过程中，中间表示必须具备足够的表达力，在不丢失信息的情况下准确表达源代码，并且充分考虑从源代码到目标代码编译的完备性、编译优化的易用性和性能。

引入中间表示后，中间表示既能面向多个前端，表达多种源程序语言，又能对接多个后端，连接不同目标机器，如 [图6.2.1](https://openmlsys.github.io/chapter_frontend_and_ir/intermediate_representation.html#intermediate-representation)所示。在此基础上，编译流程就可以在前后端直接增加更多的优化流程，这些优化流程以现有IR为输入，又以新生成的IR为输出，被称为优化器。优化器负责分析并改进中间表示，极大程度的提高了编译流程的可拓展性，也降低了优化流程对前端和后端的破坏。

[
  ](https://openmlsys.github.io/_images/中间表示-中间表示结构.png)

![img](https://openmlsys.github.io/_images/%E4%B8%AD%E9%97%B4%E8%A1%A8%E7%A4%BA-%E4%B8%AD%E9%97%B4%E8%A1%A8%E7%A4%BA%E7%BB%93%E6%9E%84.png)

1. 线性中间表示 三地址

2、图中间表示

3、混合中间表示



```
算子选择

内存复用
```



端侧AI资源和功耗限制

对于NLP，推荐场景模型很难缩小

内存限制

功耗限制

浮点计算能力限制

安装包大小限制

内存复用

模型压缩

混合精度计算

框架层轻量化



# 个人研究方向



### 端侧AI 软硬协同

{模型大小指标，

针对运行时内存指标

时延

功耗}



**内存管理是大规模深度学习发展的一个重要挑战**。深度学习中的内存管理已经成为当前深度学习系统研究的重要问题。本文将介绍深度神经网络的基本特征以及训练过程，分析深度学习中内存管理的问题，从技术的角度对一些代表性工作进行分类阐述，对比它们的优缺点，并对深度学习中内存管理的未来发展趋势进行展望。

整个神经网络的内存分配策略没有考虑到DNN分层训练的特点，这对内存资源造成了极大的浪费。





主要会议 ：MLSys





