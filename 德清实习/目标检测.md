2、IoU的计算

　　IoU是两个区域重叠的部分除以两个区域的集合部分得出的结果，通过设定的阈值，与这个IoU计算结果比较。

![image-20220328155337298](目标检测.assets/image-20220328155337298.png)

### 术语

**backbone：**

翻译为主干网络的意思，既然说是主干网络，就代表其是网络的一部分，那么是哪部分呢？这个主干网络大多时候指的是提取特征的网络，其作用就是提取图片中的信息，共后面的网络使用。这些网络经常使用的是resnet、VGG等，而不是我们自己设计的网络，因为这些网络已经证明了在分类等问题上的特征提取能力是很强的。在用这些网络作为backbone的时候，都是直接加载官方已经训练好的模型参数，后面接着我们自己的网络。让网络的这两个部分同时进行训练，因为加载的backbone模型已经具有提取特征的能力了，在我们的训练过程中，会对他进行微调，使得其更适合于我们自己的任务。

**head：**

head是获取网络输出内容的网络，利用之前提取的特征，head利用这些特征，做出预测。

**neck:**

是放在backbone和head之间的，是为了更好的利用backbone提取的特征。



neck 可以认为是 backbone 和 head 的连接层，主要负责对 backbone 的特征进行高效融合和增强，能够对输入的单尺度或者多尺度特征进行融合、增强输出等



**GAP：**

在设计的网络中经常能够看到gap这个层，我之前不知道是干啥的，后了解了，就是Global Average Pool全局平均池化，就是将某个通道的特征取平均值，经常使用AdaptativeAvgpoold(1),在pytorch中，这个代表自适应性全局平均池化，说人话就是将某个通道的特征取平均值。

```text
 self.gap = nn.AdaptiveAvgPool2d(1)
```

**Embedding**:

深度学习方法都是利用使用线性和非线性转换对复杂的数据进行自动特征抽取，并将特征表示为“向量”（vector），这一过程一般也称为“嵌入”（embedding）

**pretext task和downstream task：**
用于预训练的任务被称为前置/代理任务(pretext task)，用于微调的任务被称为下游任务(downstream task)





多尺度特征:





map

https://blog.csdn.net/HUAI_BI_TONG/article/details/121212733