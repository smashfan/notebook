1：各位评审老师早上好，



2.我的毕设题目是基于人体骨架的行为识别，。。。。。



3.下面我将从选题背景、设计流程、结论与展望三个方面介绍我的毕设，在设计流程上，我将着重介绍我的工作，包括：轻量化目标检测的实现，姿态估计方法的实现、行为识别实现、以及实时监控系统实现。



4.第一个部分：选题背景介绍。

5.基于骨骼的行为识别就是意味着，基于且仅基于时序骨架关键点序列来进行视频理解。一般传统上，关键点序列多指人体关键点序列（包括头部，双臂、躯干、下体）。

```
对图像进行人体检测
在人体上进行关键点的提取
提取的关键点在时间上形成序列堆叠
分类出动作
也就是说我们要从一下三个步骤去做研究 轻量级的目标检测、高效的姿态估计、精准的动作识别 

```



```
首先是我们的轻量级目标检测

主要工作:调研对比了单阶段YOLOv3和双阶段Faster-rcnn的目标检测算法，以及利用上轻量级网络的MobileNet V2之后的结果。测试平台为1050Ti。最后选用基于MobileNet V2的YOLOv3。

从表中，我们可以看到 DarkNet是yoloV3原有的骨干网络，在替换成mobilenetv2后，其内存占用以及推理速度上都是有明显提升
```



```
接下来是高效的姿态估计提取器。主要工作是对自顶向下（HRNet）vs自底向上（OpenPose）的对比。自顶向下就是先检测出人，再检测出关键点，自底向上的意思是先检测出关键点，再拼接成人骨架。 这里是分别两种方法的实验结果图。
实验结果表明，虽然OpenPose有较高的性能，但是效果上不如单体识别上的HRNet，由于我们需要在姿态估计上的基础上进一步行为识别，所以这里使用了更加精确的HRNet。并且自顶向下的设计方法贴切我们的设计想法。

```

```
接着是基于骨架的行为识别实现
过去使用最多的是基于图卷积的ST-GCN
但是他有一些无法避免的缺点
1.鲁棒性：输入的扰动容易对 GCN 造成较大影响，难以处理关键点缺失，泛化能力弱
2.可扩展性：GCN 所需计算量随视频中人数线性增长，很难被用于群体动作识别等应用。
```

```
所以我们使用了基于3D-CNN的行为骨架识别，它的流程为
首先，对于视频中的每一帧，我们首先使用前置（人体目标检测+姿势估计）进行二维人体骨骼提取。
然后，我们沿着时间维度堆叠关节点的（K×H×W）热图，生成的三维高斯热图（T × K×H×W ）。
最后，我们使用3D-CNN对3D热图进行特征提取，然后有全连接层和进行分类。
```



```
接下来，为了适应场景，我们利用迁移学习的方法融合业务数据
具体方法是：我们将特征提取器卷积层训练的参数冻结，替换其分类器，然后加入少量我们的数据继续训练，高效快捷的训练出场景中坐立和睡觉两个行为。效果很好。
官方通过训练了NTURGB-D数据集，基于骨架分类了60个动作，利用迁移学习的方法，高效快捷的训练出场景中坐立和睡觉两个行为。效果很好。

```



```
结论：
最后一部分结论与展望
首先可以看到左边我们的实际运行结果，其实实时效果为流程的每秒5帧。其中坐立和睡觉的识别都很准确，置信度都达到了90%以上
```



```
看到这里，大家会觉得我这5fps实用性不强，那是因为硬件平台受限，这里是我们与百度的pphuman在同一平台做对比
PP-Human是百度在今年4月开源的实时行人分析工具箱，
左边是百度用它已经落地的项目：摔倒检测，它用方案是PP-YOLOE+HRNet+ST-GCN，右边是我们同样场景跑的我们的代码
看到表格，我们发现，我们在速度上有着很强的优势
```

